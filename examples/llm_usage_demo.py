#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹ã€‚

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ yai-nexus-agentkit çš„å„ç§ LLM åŠŸèƒ½ï¼š
1. åŸºç¡€çš„ create_llm() å·¥å‚å‡½æ•°
2. å·¥å‚ç±» LLMFactory ç®¡ç†å¤šä¸ª LLM
3. æ¨¡å‹æšä¸¾çš„ç±»å‹å®‰å…¨ä½¿ç”¨
4. ä¸šåŠ¡æŠ½è±¡å±‚çš„ä¾¿æ·æ¥å£
"""

import asyncio
import os

from yai_nexus_agentkit import (
    create_llm,
    LLMFactory,
    LLMProvider,
    OpenAIModel,
    OpenRouterModel,
    DoubaoModel,
)
from langchain_core.messages import HumanMessage


async def demo_basic_usage():
    """æ¼”ç¤ºåŸºç¡€çš„ create_llm() ä½¿ç”¨ã€‚"""
    print("=== 1. åŸºç¡€ create_llm() ä½¿ç”¨ ===")

    # ä½¿ç”¨ OpenAI (éœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡)
    if os.getenv("OPENAI_API_KEY"):
        config = {
            "provider": "openai",
            "model": "gpt-3.5-turbo",
            "api_key": os.getenv("OPENAI_API_KEY"),
        }

        llm = create_llm(config)
        response = await llm.ainvoke([HumanMessage(content="Hello, what's 2+2?")])
        print(f"OpenAI å›å¤: {response.content}")
    else:
        print("è·³è¿‡ OpenAI ç¤ºä¾‹ (æœªè®¾ç½® OPENAI_API_KEY)")


async def demo_model_enums():
    """æ¼”ç¤ºæ¨¡å‹æšä¸¾çš„ç±»å‹å®‰å…¨ä½¿ç”¨ã€‚"""
    print("\n=== 2. æ¨¡å‹æšä¸¾ä½¿ç”¨ ===")

    # ä½¿ç”¨ OpenAI æ¨¡å‹æšä¸¾
    if os.getenv("OPENAI_API_KEY"):
        config = {
            "provider": LLMProvider.OPENAI.value,
            "model": OpenAIModel.GPT_3_5_TURBO.value,  # ç±»å‹å®‰å…¨çš„æ¨¡å‹é€‰æ‹©
            "api_key": os.getenv("OPENAI_API_KEY"),
        }

        llm = create_llm(config)
        response = await llm.ainvoke([HumanMessage(content="ç”¨ä¸­æ–‡å›ç­”ï¼šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")])
        print(f"ä½¿ç”¨æ¨¡å‹æšä¸¾çš„å›å¤: {response.content[:100]}...")

    # ä½¿ç”¨è±†åŒ…æ¨¡å‹æšä¸¾ (æµ‹è¯• DOUBAO_SEED_1_6_MODEL)
    if os.getenv("DOUBAO_API_KEY"):
        config = {
            "provider": LLMProvider.DOUBAO.value,
            "model": DoubaoModel.DOUBAO_SEED_1_6_MODEL.value,  # "doubao-seed-1-6-250615"
            "api_key": os.getenv("DOUBAO_API_KEY"),
        }

        llm = create_llm(config)
        response = await llm.ainvoke([HumanMessage(content="ä½ å¥½ï¼è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")])
        print(f"è±†åŒ…æ¨¡å‹ {DoubaoModel.DOUBAO_SEED_1_6_MODEL.value} å›å¤: {response.content}")
    else:
        print("è·³è¿‡è±†åŒ…ç¤ºä¾‹ (æœªè®¾ç½® DOUBAO_API_KEY)")

    # ä½¿ç”¨ OpenRouter æ¨¡å‹æšä¸¾
    if os.getenv("OPENROUTER_API_KEY"):
        config = {
            "provider": LLMProvider.OPENROUTER.value,
            "model": OpenRouterModel.GOOGLE_GEMINI_PRO.value,  # "google/gemini-pro"
            "api_key": os.getenv("OPENROUTER_API_KEY"),
            "base_url": "https://openrouter.ai/api/v1",
        }

        llm = create_llm(config)
        response = await llm.ainvoke([HumanMessage(content="Hello from Gemini!")])
        print(f"OpenRouter + Gemini å›å¤: {response.content}")
    else:
        print("è·³è¿‡ OpenRouter ç¤ºä¾‹ (æœªè®¾ç½® OPENROUTER_API_KEY)")


async def demo_llm_factory():
    """æ¼”ç¤º LLMFactory ç®¡ç†å¤šä¸ª LLMã€‚"""
    print("\n=== 3. LLMFactory å¤š LLM ç®¡ç† ===")

    configs = []

    # æ·»åŠ å¯ç”¨çš„ LLM é…ç½®
    if os.getenv("OPENAI_API_KEY"):
        configs.append(
            {
                "provider": "openai",
                "model": "gpt-3.5-turbo",
                "api_key": os.getenv("OPENAI_API_KEY"),
            }
        )

    if os.getenv("OPENROUTER_API_KEY"):
        configs.append(
            {
                "provider": "openrouter",
                "model": "google/gemini-pro",
                "api_key": os.getenv("OPENROUTER_API_KEY"),
                "base_url": "https://openrouter.ai/api/v1",
            }
        )

    if not configs:
        print("è·³è¿‡ LLMFactory ç¤ºä¾‹ (æœªè®¾ç½®ä»»ä½• API å¯†é’¥)")
        return

    # åˆ›å»ºå·¥å‚
    factory = LLMFactory(configs)
    print(f"å¯ç”¨çš„æä¾›å•†: {factory.list_providers()}")

    # ä½¿ç”¨ä¸åŒçš„ LLM
    for provider_name in factory.list_providers():
        try:
            client = factory.get_client_by_name(provider_name)
            response = await client.ainvoke([HumanMessage(content=f"Hi from {provider_name}!")])
            print(f"{provider_name} å›å¤: {response.content}")
        except Exception as e:
            print(f"{provider_name} è°ƒç”¨å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œæ‰€æœ‰ç¤ºä¾‹ã€‚"""
    print("ğŸš€ yai-nexus-agentkit LLM åŠŸèƒ½æ¼”ç¤º")
    print("è¯·ç¡®ä¿è®¾ç½®äº†ç›¸åº”çš„ API å¯†é’¥ç¯å¢ƒå˜é‡:")
    print("- OPENAI_API_KEY (ç”¨äº OpenAI ç¤ºä¾‹)")
    print("- DOUBAO_API_KEY (ç”¨äºè±†åŒ…ç¤ºä¾‹)")
    print("- OPENROUTER_API_KEY (ç”¨äº OpenRouter ç¤ºä¾‹)")
    print()

    try:
        await demo_basic_usage()
        await demo_model_enums()
        await demo_llm_factory()

        print("\nâœ… æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")

    except Exception as e:
        print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå‡ºé”™: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
