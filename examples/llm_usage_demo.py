#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹ã€‚

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ yai-nexus-agentkit çš„å„ç§ LLM åŠŸèƒ½ï¼š
1. åŸºç¡€çš„ create_llm() å·¥å‚å‡½æ•°
2. å·¥å‚ç±» LLMFactory ç®¡ç†å¤šä¸ª LLM
3. æ¨¡å‹æšä¸¾çš„ç±»å‹å®‰å…¨ä½¿ç”¨
4. ä¸šåŠ¡æŠ½è±¡å±‚çš„ä¾¿æ·æ¥å£
"""

import asyncio
import os

from yai_nexus_agentkit import (
    LLMFactory,
    LLMProvider,
    LLMConfig,
    OpenAIModel,
    OpenRouterModel,
    DoubaoModel,
)
from langchain_core.messages import HumanMessage


async def demo_basic_usage():
    """æ¼”ç¤ºåŸºç¡€çš„ LLMFactory ä½¿ç”¨ã€‚"""
    print("=== 1. åŸºç¡€ LLMFactory ä½¿ç”¨ ===")

    factory = LLMFactory()

    # ä½¿ç”¨ OpenAI (éœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡)
    if os.getenv("OPENAI_API_KEY"):
        try:
            config = LLMConfig(
                provider=LLMProvider.OPENAI,
                model=OpenAIModel.GPT_3_5_TURBO.value,
                api_key=os.getenv("OPENAI_API_KEY"),
            )

            factory.register_config("openai-basic", config)
            llm = factory.get_llm_client("openai-basic")
            response = await llm.ainvoke([HumanMessage(content="Hello, what's 2+2?")])
            print(f"OpenAI å›å¤: {response.content}")
        except Exception as e:
            print(f"OpenAI ç¤ºä¾‹å¤±è´¥: {e}")
    else:
        print("è·³è¿‡ OpenAI ç¤ºä¾‹ (æœªè®¾ç½® OPENAI_API_KEY)")


async def demo_doubao_usage():
    """æ¼”ç¤ºè±†åŒ…æ¨¡å‹ DOUBAO_SEED_1_6_MODEL çš„ä½¿ç”¨ã€‚"""
    print("\n=== 2. è±†åŒ…æ¨¡å‹ DOUBAO_SEED_1_6_MODEL æµ‹è¯• ===")

    factory = LLMFactory()

    # ä½¿ç”¨è±†åŒ…æ¨¡å‹æšä¸¾ (æµ‹è¯• DOUBAO_SEED_1_6_MODEL)
    if os.getenv("DOUBAO_API_KEY"):
        try:
            config = LLMConfig(
                provider=LLMProvider.DOUBAO,
                model=DoubaoModel.DOUBAO_SEED_1_6_MODEL.value,
                api_key=os.getenv("DOUBAO_API_KEY"),
            )

            factory.register_config("doubao-seed", config)
            llm = factory.get_llm_client("doubao-seed")
            response = await llm.ainvoke(
                [HumanMessage(content="ä½ å¥½ï¼è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")]
            )
            print(
                f"è±†åŒ…æ¨¡å‹ {DoubaoModel.DOUBAO_SEED_1_6_MODEL.value} å›å¤: {response.content}"
            )
        except Exception as e:
            print(f"è±†åŒ…æ¨¡å‹ {DoubaoModel.DOUBAO_SEED_1_6_MODEL.value} å¤±è´¥: {e}")
    else:
        print("è·³è¿‡è±†åŒ…ç¤ºä¾‹ (æœªè®¾ç½® DOUBAO_API_KEY)")


async def demo_model_enums():
    """æ¼”ç¤ºå¦‚ä½•ç»“åˆä½¿ç”¨ LLMProvider å’Œæ¨¡å‹æšä¸¾æ¥åˆ›å»º LLM å®ä¾‹ã€‚"""
    print("\n=== 2. æ¨¡å‹æšä¸¾ä½¿ç”¨ ===")
    factory = LLMFactory()

    # ä½¿ç”¨ OpenAI æ¨¡å‹æšä¸¾
    if os.getenv("OPENAI_API_KEY"):
        try:
            config = LLMConfig(
                provider=LLMProvider.OPENAI,
                model=OpenAIModel.GPT_3_5_TURBO.value,
                api_key=os.getenv("OPENAI_API_KEY"),
            )
            model_id = "openai-enum-demo"
            factory.register_config(model_id, config)
            llm = factory.get_llm_client(model_id)

            response = await llm.ainvoke(
                [HumanMessage(content="ç”¨ä¸­æ–‡å›ç­”ï¼šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")]
            )
            print(f"ä½¿ç”¨æ¨¡å‹æšä¸¾çš„å›å¤: {response.content[:100]}...")
        except Exception as e:
            print(f"OpenAI æ¨¡å‹æšä¸¾ç¤ºä¾‹å¤±è´¥: {e}")
    else:
        print("è·³è¿‡ OpenAI ç¤ºä¾‹ (æœªè®¾ç½® OPENAI_API_KEY)")

    # ä½¿ç”¨è±†åŒ…æ¨¡å‹æšä¸¾ (æµ‹è¯• DOUBAO_SEED_1_6_MODEL)
    if os.getenv("DOUBAO_API_KEY"):
        try:
            config = LLMConfig(
                provider=LLMProvider.DOUBAO,
                model=DoubaoModel.DOUBAO_SEED_1_6_MODEL.value,
                api_key=os.getenv("DOUBAO_API_KEY"),
            )
            model_id = "doubao-enum-demo"
            factory.register_config(model_id, config)
            llm = factory.get_llm_client(model_id)

            response = await llm.ainvoke(
                [HumanMessage(content="ä½ å¥½ï¼è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")]
            )
            print(
                f"è±†åŒ…æ¨¡å‹ {DoubaoModel.DOUBAO_SEED_1_6_MODEL.value} å›å¤: {response.content}"
            )
        except Exception as e:
            print(f"è±†åŒ…æ¨¡å‹æšä¸¾ç¤ºä¾‹å¤±è´¥: {e}")
    else:
        print("è·³è¿‡è±†åŒ…ç¤ºä¾‹ (æœªè®¾ç½® DOUBAO_API_KEY)")

    # ä½¿ç”¨ OpenRouter æ¨¡å‹æšä¸¾
    if os.getenv("OPENROUTER_API_KEY"):
        try:
            config = LLMConfig(
                provider=LLMProvider.OPENROUTER,
                model=OpenRouterModel.GOOGLE_GEMINI_PRO.value,
                api_key=os.getenv("OPENROUTER_API_KEY"),
                base_url="https://openrouter.ai/api/v1",
            )
            model_id = "openrouter-enum-demo"
            factory.register_config(model_id, config)
            llm = factory.get_llm_client(model_id)

            response = await llm.ainvoke([HumanMessage(content="Hello from Gemini!")])
            print(f"OpenRouter + Gemini å›å¤: {response.content}")
        except Exception as e:
            print(f"OpenRouter æ¨¡å‹æšä¸¾ç¤ºä¾‹å¤±è´¥: {e}")
    else:
        print("è·³è¿‡ OpenRouter ç¤ºä¾‹ (æœªè®¾ç½® OPENROUTER_API_KEY)")


async def demo_llm_factory():
    """æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ LLMFactory åŒæ—¶ç®¡ç†å¤šä¸ª LLM é…ç½®ã€‚"""
    print("\n=== 3. LLMFactory å¤š LLM ç®¡ç† ===")

    # 1. å®šä¹‰å¤šä¸ªæ¨¡å‹é…ç½®
    # æ³¨æ„: provider çš„å€¼å¿…é¡»æ˜¯ LLMProvider æšä¸¾æˆå‘˜ï¼Œè€Œä¸æ˜¯å­—ç¬¦ä¸²
    configs = {
        "chat_model": LLMConfig(
            provider=LLMProvider.OPENAI,
            model=OpenAIModel.GPT_3_5_TURBO.value,
            api_key=os.getenv("OPENAI_API_KEY"),
        ),
        "backup_model": LLMConfig(
            provider=LLMProvider.OPENROUTER,
            model=OpenRouterModel.GOOGLE_GEMINI_PRO.value,
            api_key=os.getenv("OPENROUTER_API_KEY"),
        ),
    }

    # 2. æ³¨å†Œé…ç½®åˆ°å·¥å‚
    factory = LLMFactory()
    for model_id, config_obj in configs.items():
        # åªæœ‰åœ¨æä¾›äº† api_key æ—¶æ‰æ³¨å†Œ
        if config_obj.api_key:
            factory.register_config(model_id, config_obj)
        else:
            print(f"è·³è¿‡æ³¨å†Œæ¨¡å‹ '{model_id}' (æœªæä¾› API Key)")

    # 3. ä»å·¥å‚è·å–å¹¶ä½¿ç”¨ä¸åŒçš„ LLM å®¢æˆ·ç«¯
    # ä»…å½“ OPENAI_API_KEY å¯ç”¨æ—¶æ‰å°è¯•è·å–
    if "chat_model" in factory._configs:
        try:
            chat_llm = factory.get_llm_client("chat_model")
            response = await chat_llm.ainvoke("Say 'Hello'")
            print(f"Chat Model (OpenAI) response: {response.content}")
        except Exception as e:
            print(f"ä½¿ç”¨ 'chat_model' å¤±è´¥: {e}")

    # ä»…å½“ OPENROUTER_API_KEY å¯ç”¨æ—¶æ‰å°è¯•è·å–
    if "backup_model" in factory._configs:
        try:
            backup_llm = factory.get_llm_client("backup_model")
            response = await backup_llm.ainvoke("Say 'Hi' in German")
            print(f"Backup Model (OpenRouter) response: {response.content}")
        except Exception as e:
            print(f"ä½¿ç”¨ 'backup_model' å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œæ‰€æœ‰ç¤ºä¾‹ã€‚"""
    print("ğŸš€ yai-nexus-agentkit LLM åŠŸèƒ½æ¼”ç¤º")
    print("è¯·ç¡®ä¿è®¾ç½®äº†ç›¸åº”çš„ API å¯†é’¥ç¯å¢ƒå˜é‡:")
    print("- OPENAI_API_KEY (ç”¨äº OpenAI ç¤ºä¾‹)")
    print("- DOUBAO_API_KEY (ç”¨äºè±†åŒ…ç¤ºä¾‹)")
    print("- OPENROUTER_API_KEY (ç”¨äº OpenRouter ç¤ºä¾‹)")
    print()

    try:
        await demo_basic_usage()
        await demo_doubao_usage()
        await demo_model_enums()
        await demo_llm_factory()

        print("\nâœ… æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")

    except Exception as e:
        print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå‡ºé”™: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
